{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d010bbad-6ffe-4065-b1c6-17e9815f72b9",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea708048-37bc-4170-95b7-b1f0be3ab5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc3059-ee44-43fc-b297-b096d1b6cd16",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983567e-4e5a-4151-8b5a-74c08e086c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dados/diabetes_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df576e-f9c7-4672-9fc2-c1ce12cfa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = pd.read_csv('../dados/diabetes_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad8a62-7769-4afa-a30c-cd9b79a985ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae454e-be92-444d-a00d-030d178c6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eceae2-b3dd-4a56-a6e2-52addfdac2db",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ff315-9ce5-4e59-afee-fb59d753acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = 'Diabetes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1701962-e29f-4b24-b634-59faa885e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = df_cols[df_cols['column'] != TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ae576-b276-49f3-8c25-3d94b4beb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Feature Groups\n",
    "numeric_feats = list(df_cols.loc[df_cols['type'] == 'Float', 'column'].values)\n",
    "nominal_feats = list(df_cols.loc[df_cols['type'] == 'Categorical', 'column'].values) # Unordered\n",
    "ordinal_feats = list(df_cols.loc[df_cols['type'] == 'Ordinal', 'column'].values)    # Ordered\n",
    "boolean_feats = list(df_cols.loc[df_cols['type'] == 'Boolean', 'column'].values) # Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723f0ff-5478-4638-966f-b37fecbd652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Transformers\n",
    "\n",
    "# A. Nominal: Use OneHotEncoder\n",
    "nominal_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# B. Ordinal: Use OrdinalEncoder with defined categories\n",
    "# Note: You must list the categories in ascending order for each ordinal column\n",
    "# Here: Junior (0) < Mid (1) < Senior (2)\n",
    "ordinal_transformer = OrdinalEncoder(categories='auto')\n",
    "\n",
    "# C. Boolean: Use OrdinalEncoder (maps No->0, Yes->1 alphabetically usually)\n",
    "# Or define explicit order like below to be safe: ['No', 'Yes'] maps to 0 and 1\n",
    "boolean_transformer = OrdinalEncoder(categories='auto')\n",
    "\n",
    "# D. Numeric: Standard Scaler\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# 4. Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_feats),\n",
    "        ('nom', nominal_transformer, nominal_feats),\n",
    "        ('ord', ordinal_transformer, ordinal_feats),\n",
    "        ('bool', boolean_transformer, boolean_feats)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ec351-f5ae-4dfb-92d5-9ad47c949b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build Pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Test it immediately\n",
    "X = df.drop(TARGET_COL, axis=1)\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b5ecb-4242-474c-ac52-d570352c5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afe8b0-90dc-46bd-9801-8469ff2ac34d",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939236a2-af0c-4e97-80ad-d33a10dfccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline (preprocessing + training happens here)\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"### Hold-out Test Evaluation ###\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b3822-7edf-4c9e-ba65-35086da80400",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1b1e4-457d-4908-b574-765bde79ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a specific folder for temporary joblib files\n",
    "os.makedirs('./joblib_temp', exist_ok=True)\n",
    "os.environ['JOBLIB_TEMP_FOLDER'] = './joblib_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492bfd2-e9cd-41a3-8d07-ef2944ccf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# 1. Define the grid of hyperparameters to search\n",
    "# Note the prefix 'classifier__' matching the name in your Pipeline steps\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 300, 500],\n",
    "    'classifier__max_depth': [None, 10, 30],\n",
    "    'classifier__min_samples_split': [2, 10, 20],\n",
    "    'classifier__min_samples_leaf': [2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__criterion': ['gini']\n",
    "}\n",
    "\n",
    "# 2. Initialize RandomizedSearchCV\n",
    "# n_iter=50 means it will try 50 random combinations (adjust for speed vs accuracy)\n",
    "# cv=3 means it uses 3-fold cross-validation for every try\n",
    "# scoring='f1_macro' for prioritizing rare predictions\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='f1_macro',\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "print(\"### Starting Hyperparameter Optimization ###\")\n",
    "# 3. Fit the search object (this takes time!)\n",
    "with joblib.parallel_backend('threading'):\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "#random_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Results\n",
    "print(f\"\\nBest Parameter Combination Found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "print(f\"\\nBest Cross-Validation Score (F1 Macro): {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 5. Update your pipeline to be the best estimator found\n",
    "best_model_pipeline = random_search.best_estimator_\n",
    "\n",
    "# Now you can proceed to predict using 'best_model_pipeline'\n",
    "print(\"\\nValidating on Test Set with Best Model...\")\n",
    "y_pred_optimized = best_model_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9388477-d019-4527-ab20-c046e57bdd13",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18df06-294d-4ec8-88cf-90697c47daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 3-Fold Stratified Cross-Validation\n",
    "# Stratified ensures the ratio of Target 0s and 1s is preserved in each fold\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "print(\"### Starting 3-Fold Backtest ###\\n\")\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split data for this fold\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Clone the pipeline to ensure a fresh model for each fold\n",
    "    from sklearn.base import clone\n",
    "    fold_pipeline = clone(best_model_pipeline)\n",
    "    \n",
    "    # Train\n",
    "    fold_pipeline.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_fold = fold_pipeline.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    prec = precision_score(y_test_fold, y_pred_fold, average='macro',  zero_division=0)\n",
    "    rec = recall_score(y_test_fold, y_pred_fold, average='macro',  zero_division=0)\n",
    "    f1 = f1_score(y_test_fold, y_pred_fold, average='macro', zero_division=0)\n",
    "    \n",
    "    # Store and Print\n",
    "    fold_results.append({'Fold': i+1, 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1': f1})\n",
    "    print(f\"Fold {i+1}: Accuracy={acc:.2f} | Precision={prec:.2f} | Recall={rec:.2f} | F1={f1:.2f}\")\n",
    "\n",
    "# Average Performance\n",
    "avg_acc = np.mean([res['Accuracy'] for res in fold_results])\n",
    "print(f\"\\nAverage Accuracy across 3 folds: {avg_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f1b6b-48ef-46ea-99de-09233da31c6d",
   "metadata": {},
   "source": [
    "# Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d138fa-46b6-4243-b51a-1e07ff89b4aa",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2050b1-5648-498c-bba4-918faec595be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Access the classifier step from the pipeline\n",
    "# 'classifier' is the name we gave it in the Pipeline definition\n",
    "rf_model = model_pipeline.named_steps['classifier']\n",
    "\n",
    "# 2. Get the feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# 3. Get the feature names from the preprocessor\n",
    "# This is crucial because OneHotEncoder adds new columns\n",
    "feature_names = model_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# 4. Create a DataFrame to organize the data\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# 5. Sort by importance (descending)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 6. Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('Random Forest Feature Importances (Gini Importance)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Print the top 5 features\n",
    "print(\"Top 5 Features:\")\n",
    "print(feature_importance_df.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbd7b2-9b5c-4495-8dec-d6ee14b49657",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9fd307-89cf-49da-8d11-979ec4d4be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'model_pipeline' is your fitted pipeline\n",
    "# (e.g., from Section 2 or 3 of the previous code)\n",
    "\n",
    "# Define the file path\n",
    "pipeline_filename = 'trained_classification_pipeline.joblib'\n",
    "\n",
    "# Save the pipeline object\n",
    "joblib.dump(model_pipeline, pipeline_filename)\n",
    "\n",
    "print(f\"âœ… Pipeline successfully saved to {pipeline_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e243b4-9076-4dc1-9121-ad7af26708d4",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a80f3-f2ab-47f5-b891-aced19346933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_csv('../dados/diabetes_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fdd13-31ba-4c03-9005-41f2fb97cf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47dc14-f0ec-4618-8284-bd991f90563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the main fitted pipeline\n",
    "df_predict['prediction'] = model_pipeline.predict(df_predict)\n",
    "df_predict_final = pd.concat([df_predict, pd.DataFrame(model_pipeline.predict_proba(df_predict)).add_prefix('prob_')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7492076-24e0-43fd-8404-3cc28e8850fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
